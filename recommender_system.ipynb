{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "id_column = \"id\"\n",
    "content_column = \"description\"\n",
    "document_path = \"./sample-data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Start time to read document is %s:  2020-02-03 10:10:26.211532\nEnd time to read document is %s:  2020-02-03 10:10:26.224452\nTime taken to read the document is %s:  0:00:00.012920\n"
    },
    {
     "data": {
      "text/plain": "500"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the document\n",
    "t1 = datetime.datetime.now()\n",
    "print(\"Start time to read document is %s: \", t1)\n",
    "\n",
    "ds = pd.read_csv(document_path)\n",
    "\n",
    "t2 = datetime.datetime.now()\n",
    "print(\"End time to read document is %s: \", t2)\n",
    "\n",
    "print(\"Time taken to read the document is %s: \", t2 - t1)\n",
    "\n",
    "len(ds)\n",
    "# ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Start time to TfIdf is %s:  2020-02-03 10:10:28.111828\nEnd time to TfIdf is %s:  2020-02-03 10:10:28.118228\nTime taken to TfIdf is %s:  0:00:00.006400\nTfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n                dtype=<class 'numpy.float64'>, encoding='utf-8',\n                input='content', lowercase=True, max_df=1.0, max_features=None,\n                min_df=0, ngram_range=(1, 1), norm='l2', preprocessor=None,\n                smooth_idf=True, stop_words='english', strip_accents=None,\n                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                tokenizer=None, use_idf=True, vocabulary=None)\n"
    }
   ],
   "source": [
    "# Document vectorization\n",
    "\n",
    "t1 = datetime.datetime.now()\n",
    "print(\"Start time to TfIdf is %s: \", t1)\n",
    "\n",
    "tf = TfidfVectorizer(analyzer='word', min_df=0, stop_words='english')\n",
    "\n",
    "t2 = datetime.datetime.now()\n",
    "print(\"End time to TfIdf is %s: \", t2)\n",
    "\n",
    "print(\"Time taken to TfIdf is %s: \", t2 - t1)\n",
    "\n",
    "print(tf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Start time to compute fit_transform is %s:  2020-02-03 10:10:30.038178\nEnd time to compute fit_transform is %s:  2020-02-03 10:10:30.159043\nTime taken to compute fit_transform is %s:  0:00:00.120865\n"
    }
   ],
   "source": [
    "# Transform the content as matrix\n",
    "\n",
    "t1 = datetime.datetime.now()\n",
    "print(\"Start time to compute fit_transform is %s: \", t1)\n",
    "\n",
    "tfidf_matrix = tf.fit_transform(ds[content_column])\n",
    "\n",
    "t2 = datetime.datetime.now()\n",
    "print(\"End time to compute fit_transform is %s: \", t2)\n",
    "        \n",
    "print(\"Time taken to compute fit_transform is %s: \", t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Start time to compute similarities is %s:  2020-02-03 10:10:31.358448\nEnd time to compute similarities is %s:  2020-02-03 10:10:31.412595\nTime taken to compute similarities is %s:  0:00:00.054147\n"
    }
   ],
   "source": [
    "# Compute the similarity\n",
    "\n",
    "t1 = datetime.datetime.now()\n",
    "print(\"Start time to compute similarities is %s: \", t1)\n",
    "cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "\n",
    "t2 = datetime.datetime.now()\n",
    "print(\"End time to compute similarities is %s: \", t2)\n",
    "        \n",
    "print(\"Time taken to compute similarities is %s: \", t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Start time to calculate result is %s:  2020-02-03 10:09:37.092305\nEnd time to calculate result is %s:  2020-02-03 10:09:38.436373\nTime taken to calculate result is %s:  0:00:01.344068\n"
    }
   ],
   "source": [
    "# Find the result\n",
    "\n",
    "results = {}\n",
    "\n",
    "t1 = datetime.datetime.now()\n",
    "print(\"Start time to calculate result is %s: \", t1)\n",
    "\n",
    "for idx, row in ds.iterrows():\n",
    "    similar_indices = cosine_similarities[idx].argsort()[:-100:-1]\n",
    "    similar_items = [(cosine_similarities[idx][i], ds[id_column][i]) for i in similar_indices]\n",
    "\n",
    "    results[row[id_column]] = similar_items[1:]\n",
    "    \n",
    "t2 = datetime.datetime.now()\n",
    "print(\"End time to calculate result is %s: \", t2)\n",
    "\n",
    "print(\"Time taken to calculate result is %s: \", t2 - t1)\n",
    "\n",
    "def item(id):\n",
    "    return ds.loc[ds[id_column] == id][content_column].tolist()[0].split(' - ')[0]\n",
    "\n",
    "# Just reads the results out of the dictionary.\n",
    "def recommend(id, num):\n",
    "    print(\"Recommending \" + str(num) + \" products similar to \" + item(id) + \"...\")\n",
    "    print(\"-------\")\n",
    "    recs = results[id][:num]\n",
    "    for rec in recs:\n",
    "        print(\"Recommended: \" + item(rec[1]) + \" (score:\" + str(rec[0]) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Start time to recommend is %s:  2020-02-03 10:10:33.270830\nRecommending 10 products similar to Cap 1 graphic t-shirt...\n-------\nRecommended: Cap 1 graphic t-shirt (score:0.8346122195247042)\nRecommended: Cap 1 graphic crew (score:0.772584528935399)\nRecommended: Cap 1 crew (score:0.7081061617160098)\nRecommended: Cap 1 t-shirt (score:0.7059855757125564)\nRecommended: Cap 1 t-shirt (score:0.6785025221080636)\nRecommended: Cap 1 scoop (score:0.6466990537133701)\nRecommended: Cap 1 bottoms (score:0.5549528755979624)\nRecommended: Cap 1 bottoms (score:0.549142080509303)\nRecommended: Cap 1 graphic tee (score:0.540730700077156)\nRecommended: Cap 2 cap sleeve (score:0.3706066482662903)\nEnd time to recommend is %s:  2020-02-03 10:10:33.336938\nTime taken to recommend is %s:  0:00:00.066108\n"
    }
   ],
   "source": [
    "t1 = datetime.datetime.now()\n",
    "print(\"Start time to recommend is %s: \", t1)\n",
    "\n",
    "recommend(id=20, num=10)\n",
    "\n",
    "t2 = datetime.datetime.now()\n",
    "print(\"End time to recommend is %s: \", t2)\n",
    "\n",
    "print(\"Time taken to recommend is %s: \", t2 - t1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}